/**
 * Project Serializer
 * Serializes and deserializes project state from Zustand stores
 */

import { useArrangementStore } from '@/store/useArrangementStore';
import { useArrangementV2Store } from '@/store/useArrangementV2Store';
import { useInstrumentsStore } from '@/store/useInstrumentsStore';
import { useMixerStore } from '@/store/useMixerStore';
import { usePlaybackStore } from '@/store/usePlaybackStore';
import { useTimelineStore } from '@/store/TimelineStore';
import { useProjectAudioStore } from '@/store/useProjectAudioStore';
import { useArrangementWorkspaceStore } from '@/store/useArrangementWorkspaceStore';
import { storageService } from '@/services/storage.js';
import { normalizeEffectSettings } from '@/lib/audio/effects/parameterMappings.js';
import { getAutomationManager } from '@/lib/automation/AutomationManager.js';

export class ProjectSerializer {
  static CURRENT_VERSION = '1.0.0';

  /**
   * Create empty project template with default setup
   * - 4 instruments in channel rack: kick, snare, hihat, 808
   * - 20 mixer channels (channel-1 to channel-20), colored in groups of 5
   * - 20 arrangement tracks
   */
  static createEmptyProjectTemplate() {
    // Color palette for mixer channels (5 colors, repeated 4 times for 20 channels)
    const mixerColors = [
      '#ef4444', // Red
      '#3b82f6', // Blue
      '#10b981', // Green
      '#f59e0b', // Orange
      '#8b5cf6', // Purple
    ];

    // Create 4 default instruments
    // Format matches what handleAddNewInstrument expects
    const instruments = [
      {
        id: 'kick-1',
        name: 'Kick',
        type: 'sample',
        url: '/audio/samples/drums/kick.wav',
        mixerTrackId: 'track-1',
        color: '#ef4444',
      },
      {
        id: 'snare-1',
        name: 'Snare',
        type: 'sample',
        url: '/audio/samples/drums/snare.wav',
        mixerTrackId: 'track-2',
        color: '#3b82f6',
      },
      {
        id: 'hihat-1',
        name: 'Hi-Hat',
        type: 'sample',
        url: '/audio/samples/drums/hihat.wav',
        mixerTrackId: 'track-3',
        color: '#10b981',
      },
      {
        id: '808-1',
        name: '808',
        type: 'sample',
        url: '/audio/samples/drums/808.wav',
        mixerTrackId: 'track-4',
        color: '#f59e0b',
      },
    ];

    // Create 20 mixer channels (channel-1 to channel-20)
    const mixerTracks = [
      // Master channel
      {
        id: 'master',
        name: 'Master',
        type: 'master',
        volume: 0,
        pan: 0,
        muted: false,
        solo: false,
        color: '#8b5cf6',
        output: null,
        sends: [],
        insertEffects: [],
        eq: { enabled: false, lowGain: 0, midGain: 0, highGain: 0 },
      },
      // 20 channel tracks (channel-1 to channel-20)
      ...Array.from({ length: 20 }, (_, i) => ({
        id: `track-${i + 1}`,
        name: `channel-${i + 1}`,
        type: 'track', // âœ… FIX: Use 'track' to match Mixer.jsx filter
        volume: 0,
        pan: 0,
        muted: false,
        solo: false,
        color: mixerColors[i % 5], // 5 colors, repeated
        output: 'master',
        sends: [],
        insertEffects: [],
        eq: { enabled: false, lowGain: 0, midGain: 0, highGain: 0 },
      })),
    ];

    // Create 20 arrangement tracks
    const arrangementTracks = Array.from({ length: 20 }, (_, i) => ({
      id: `arr-track-${i + 1}`,
      name: `Track ${i + 1}`,
      height: 80,
      volume: 1.0,
      pan: 0,
      muted: false,
      solo: false,
      locked: false,
      collapsed: false,
    }));

    return {
      metadata: {
        version: this.CURRENT_VERSION,
        dawg_version: '0.0.0',
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString(),
        bpm: 120,
        time_signature: '4/4',
        key_signature: null,
      },
      instruments,
      patterns: {
        'pattern-1': {
          id: 'pattern-1',
          name: 'Pattern 1',
          data: {}, // Empty pattern data: { instrumentId: [notes] }
          length: 64, // Default pattern length (4 bars)
          settings: {
            quantization: '16n'
          }
        }
      },
      pattern_order: ['pattern-1'],
      active_pattern_id: 'pattern-1',
      arrangement: {
        tracks: arrangementTracks,
        clips: [],
        markers: [],
        loop_regions: [],
      },
      mixer: {
        tracks: mixerTracks.filter(t => t.type !== 'master'),
        send_channels: [],
        master: mixerTracks.find(t => t.type === 'master'),
      },
      timeline: {
        total_beats: 64,
        total_bars: 4,
        zoom: { x: 1, y: 1 },
        snap_mode: 'grid',
        grid_size: '1/4',
      },
      audio_assets: [],
      workspace: {
        viewMode: 'pattern',
        selectedTrackId: null,
        selectedClipIds: [],
      },
    };
  }

  /**
   * Serialize current state from all stores
   */
  static serializeCurrentState() {
    const arrangementStore = useArrangementStore.getState();
    const instrumentsStore = useInstrumentsStore.getState();
    const mixerStore = useMixerStore.getState();
    const playbackStore = usePlaybackStore.getState();
    const timelineStore = useTimelineStore.getState();
    const projectAudioStore = useProjectAudioStore.getState();
    const workspaceStore = useArrangementWorkspaceStore.getState();

    return {
      metadata: {
        version: this.CURRENT_VERSION,
        dawg_version: import.meta.env.VITE_APP_VERSION || '0.0.0',
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString(),
        bpm: playbackStore.bpm || 120,
        time_signature: playbackStore.timeSignature || '4/4',
        key_signature: playbackStore.keySignature,
      },

      instruments: this.serializeInstruments(instrumentsStore, projectAudioStore),
      patterns: this.serializePatterns(arrangementStore),
      pattern_order: arrangementStore.patternOrder || [],
      
      arrangement: {
        tracks: this.serializeArrangementTracks(arrangementStore),
        clips: this.serializeArrangementClips(arrangementStore),
        markers: arrangementStore.markers || [],
        loop_regions: arrangementStore.loopRegions || [],
      },

      mixer: {
        tracks: this.serializeMixerTracks(mixerStore),
        send_channels: mixerStore.sendChannels || [],
        master: this.serializeMasterChannel(mixerStore),
      },

      timeline: {
        // âœ… FIX: TimelineStore doesn't have totalBeats/totalBars properties
        // These are calculated from arrangement or use defaults
        total_beats: 64, // Default: 4 bars * 16 steps per bar
        total_bars: 4, // Default: 4 bars
        zoom: { x: 1, y: 1 }, // Default zoom
        snap_mode: 'grid', // Default snap mode
        grid_size: '1/4', // Default grid size (16th notes)
      },

      audio_assets: this.serializeAudioAssets(projectAudioStore),
      workspace: this.serializeWorkspace(workspaceStore),
    };
  }

  /**
   * Serialize project data (for saving)
   */
  static serialize(projectData) {
    // If projectData is already serialized, return as is
    if (projectData.metadata && projectData.instruments) {
      return projectData;
    }

    // Otherwise serialize current state
    return this.serializeCurrentState();
  }

  /**
   * Clear all project data from stores (before loading new project)
   */
  static async clearAll() {
    console.log('ğŸ§¹ Clearing all project data from stores...');
    
    try {
      // âœ… FIX: Get active instrument URLs for buffer cleanup
      const instrumentsStore = useInstrumentsStore.getState();
      const activeUrls = new Set();
      const instruments = instrumentsStore.instruments || [];
      
      instruments.forEach(inst => {
        if (inst.url) activeUrls.add(inst.url);
        if (inst.multiSamples) {
          inst.multiSamples.forEach(sample => {
            if (sample.url) activeUrls.add(sample.url);
          });
        }
      });
      
      // Clear audio engine instruments and buffers FIRST
      const { AudioContextService } = await import('../services/AudioContextService.js');
      const engine = AudioContextService.getAudioEngine();
      if (engine) {
        // Clear instruments from audio engine
        if (engine.instruments) {
          const instrumentIds = Array.from(engine.instruments.keys());
          instrumentIds.forEach(id => {
            try {
              if (engine.removeInstrument) {
                engine.removeInstrument(id);
              } else if (AudioContextService.removeInstrument) {
                AudioContextService.removeInstrument(id);
              }
            } catch (e) {
              console.warn(`âš ï¸ Failed to remove engine instrument ${id}:`, e);
            }
          });
        }
        
        // âœ… FIX: Clear ALL sample buffers when switching projects (not just unused)
        // This ensures clean state for new project
        if (engine.sampleBuffers) {
          engine.sampleBuffers.clear();
          console.log('ğŸ§¹ Cleared all sample buffers from audio engine');
        }
        
        // âœ… FIX: Clear ALL cache in SampleLoader when switching projects
        const { SampleLoader } = await import('../audio/instruments/loaders/SampleLoader.js');
        SampleLoader.clearCache();
      }
      
      // Clear instruments from store (direct state update)
      useInstrumentsStore.setState({
        instruments: [],
        channelOrder: [],
        selectedChannels: [],
        processingEffects: {}
      });
      
      // Clear mixer tracks (except master) - use removeTrack method
      const mixerStore = useMixerStore.getState();
      const mixerTracks = mixerStore.mixerTracks || [];
      const tracksToRemove = mixerTracks.filter(track => track.id !== 'master');
      
      // Remove tracks in reverse order to avoid dependency issues
      tracksToRemove.reverse().forEach(track => {
        try {
          mixerStore.removeTrack(track.id);
        } catch (e) {
          console.warn(`âš ï¸ Failed to remove mixer track ${track.id}:`, e);
        }
      });
      
      // âœ… FIX: Clear ALL patterns completely (don't use deletePattern which keeps at least one)
      // Directly reset patterns state to empty object
      useArrangementStore.setState({
        patterns: {},
        patternOrder: [],
        activePatternId: null, // Will be set when new project loads
        nextPatternNumber: 1, // Reset pattern numbering
      });
      
      // Clear arrangement tracks and clips
      // âœ… FIX: Use Zustand store's setState method (not from getState())
      useArrangementStore.setState({
        arrangementTracks: [],
        arrangementClips: [],
        arrangementMarkers: [],
        arrangementLoopRegions: []
      });
      
      // Clear timeline
      // âœ… FIX: TimelineStore doesn't have setTotalBars/setTotalBeats methods
      // Timeline state is managed through markers, loop regions, etc.
      // Just reset to defaults if needed
      useTimelineStore.setState({
        markers: [],
        loopRegions: [],
        activeLoopRegionId: null
      });
      
      // Clear audio assets
      const audioStore = useProjectAudioStore.getState();
      audioStore.clearAll();
      
      // Clear workspace
      // âœ… FIX: Workspace state is in useArrangementStore, not useArrangementWorkspaceStore
      // Reset workspace selection state
      useArrangementStore.setState({
        selectedClipIds: [],
        // viewMode and selectedTrackId might not exist in store, but we'll try to reset if they do
      });
      
      // âœ… FIX: Stop playback and reset position when switching projects
      const playbackStore = usePlaybackStore.getState();
      if (playbackStore.isPlaying) {
        playbackStore.handleStop?.();
      }
      if (playbackStore.jumpToStep) {
        playbackStore.jumpToStep(0);
      }
      
      console.log('âœ… All project data cleared');
    } catch (error) {
      console.error('âŒ Failed to clear project data:', error);
      throw error;
    }
  }

  /**
   * Deserialize project data and restore to stores
   */
  static async deserialize(projectData) {
    if (!projectData || typeof projectData !== 'object') {
      throw new Error('Invalid project data');
    }

    // âœ… FIX: Don't call clearAll() here - it's already called in handleProjectSelect
    // This prevents double-clearing and ensures clean state

    // Restore to stores in correct order:
    // 1. Mixer tracks FIRST (instruments need mixer inserts to route to)
    // 2. Preload samples BEFORE creating instruments (instruments need buffers)
    // 3. Instruments (need mixer inserts and buffers to exist)
    // 4. Patterns (need instruments to exist)
    // 5. Arrangement (needs patterns and tracks)
    
    if (projectData.mixer) {
      await this.deserializeMixer(projectData.mixer);
    }

    // âœ… CRITICAL FIX: Sync mixer tracks to AudioEngine after deserialization
    // This ensures mixer inserts exist before instruments are created
    const { AudioContextService } = await import('../services/AudioContextService.js');
    await AudioContextService._syncMixerTracksToAudioEngine();

    if (projectData.audio_assets) {
      this.deserializeAudioAssets(projectData.audio_assets);
    }

    // âœ… CRITICAL FIX: Preload samples BEFORE creating instruments
    // This ensures buffers are available when instruments are created
    if (projectData.instruments) {
      await this._preloadProjectSamples(projectData);
    }

    if (projectData.instruments) {
      this.deserializeInstruments(projectData.instruments);
    }

    // âœ… CRITICAL FIX: Sync instruments to mixer inserts AFTER deserializing instruments
    // This ensures instruments are properly routed to their mixer tracks
    await AudioContextService._syncInstrumentsToMixerInserts();

    // âœ… CRITICAL FIX: Re-sync mixer tracks after instruments are loaded
    // This ensures send connections are properly established with all inserts ready
    await AudioContextService._syncMixerTracksToAudioEngine();

    if (projectData.patterns) {
      this.deserializePatterns(projectData.patterns);
    }
    
    // âœ… FIX: Always restore pattern order and active pattern
    // If not provided, will default to first pattern
    this.deserializePatternOrder(projectData.pattern_order, projectData.active_pattern_id);

    if (projectData.arrangement) {
      this.deserializeArrangement(projectData.arrangement);
    }

    if (projectData.timeline) {
      this.deserializeTimeline(projectData.timeline);
    }

    if (projectData.workspace) {
      this.deserializeWorkspace(projectData.workspace);
    }

    // Restore playback settings
    if (projectData.metadata) {
      const playbackStore = usePlaybackStore.getState();

      if (projectData.metadata.bpm) {
        const restoredBpm = Number(projectData.metadata.bpm) || 120;

        // âœ… Update Zustand state immediately so helper utilities read the correct BPM
        usePlaybackStore.setState({ bpm: restoredBpm });

        try {
          const { AudioContextService } = await import('../services/AudioContextService.js');
          // Always push BPM to the currently active audio engine
          if (typeof AudioContextService.setBPM === 'function') {
            AudioContextService.setBPM(restoredBpm);
          } else {
            const engine = AudioContextService.getAudioEngine?.();
            engine?.setBPM?.(restoredBpm);
          }

          // Only route through PlaybackController when it's bound to the same engine
          const controller = playbackStore._controller;
          const currentEngine = AudioContextService.getAudioEngine?.();
          if (controller && controller.audioEngine === currentEngine && typeof controller.setBPM === 'function') {
            controller.setBPM(restoredBpm);
          }
        } catch (error) {
          console.warn('âš ï¸ Failed to sync BPM to audio engine during project restore:', error);
        }
      }

      if (projectData.metadata.time_signature) {
        console.log(`âœ… Restored BPM: ${projectData.metadata.bpm}, Time Signature: ${projectData.metadata.time_signature}`);
      }
    }

    console.log('âœ… Project deserialization complete');
    
    // âœ… FIX: Sample preloading is now done BEFORE instrument creation
    // This ensures buffers are available when instruments are created
    // No need to preload again here
    
    return projectData;
  }

  /**
   * Preload and buffer all samples used in the project
   * âœ… NEW: Uses ProjectBufferManager for efficient buffer management
   * @private
   */
  static async _preloadProjectSamples(projectData) {
    try {
      const instruments = projectData.instruments || [];
      if (instruments.length === 0) {
        return;
      }

      const { AudioContextService } = await import('../services/AudioContextService.js');
      const engine = AudioContextService.getAudioEngine();
      if (!engine || !engine.audioContext) {
        console.warn('âš ï¸ Cannot preload samples: audio engine not ready');
        return;
      }

      // âœ… NEW: Use ProjectBufferManager for efficient buffer management
      const { getProjectBufferManager } = await import('../audio/ProjectBufferManager.js');
      const bufferManager = getProjectBufferManager();

      console.log(`ğŸ“¦ Preloading samples for ${instruments.length} instruments...`);
      
      // Collect all sample URLs
      const sampleUrls = new Set();
      instruments.forEach(inst => {
        if (inst.url) sampleUrls.add(inst.url);
        if (inst.multiSamples) {
          inst.multiSamples.forEach(sample => {
            if (sample.url) sampleUrls.add(sample.url);
          });
        }
      });

      // âœ… NEW: Preload using ProjectBufferManager (checks cache first)
      const preloadPromises = Array.from(sampleUrls).map(async (url) => {
        try {
          // ProjectBufferManager checks cache first, only loads if needed
          const buffer = await bufferManager.getBuffer(url, engine.audioContext);
          
          // Also add to SampleLoader cache for compatibility
          const { SampleLoader } = await import('../audio/instruments/loaders/SampleLoader.js');
          SampleLoader.cache.set(url, buffer);
          
          return buffer;
        } catch (error) {
          console.warn(`âš ï¸ Failed to preload sample ${url}:`, error);
          return null;
        }
      });

      await Promise.allSettled(preloadPromises);
      
      // Preload samples in audio engine for instruments
      const sampleInstruments = instruments.filter(inst => inst.type === 'sample' && (inst.url || inst.multiSamples));
      if (sampleInstruments.length > 0 && engine.preloadSamples) {
        await engine.preloadSamples(sampleInstruments);
      }

      // âœ… CRITICAL FIX: Update existing instrument buffers after preloading
      // This ensures that instruments created before sample loading get their buffers
      sampleInstruments.forEach(inst => {
        try {
          const instrument = engine.instruments?.get(inst.id);
          if (instrument && engine.sampleBuffers?.has(inst.id)) {
            const buffer = engine.sampleBuffers.get(inst.id);
            if (instrument.buffer !== buffer) {
              instrument.buffer = buffer;
              console.log(`âœ… Updated buffer for instrument ${inst.id} (${inst.name})`);
            }
          }
        } catch (error) {
          console.warn(`âš ï¸ Failed to update buffer for instrument ${inst.id}:`, error);
        }
      });

      const stats = bufferManager.getStats();
      console.log(`âœ… Preloaded ${sampleUrls.size} samples for project (${stats.totalMB}MB cached)`);
    } catch (error) {
      console.error('âŒ Failed to preload project samples:', error);
      // Don't throw - sample loading can happen lazily
    }
  }

  // =================== SERIALIZATION HELPERS ===================

  static serializeInstruments(store, audioStore) {
    const assetMap = new Map();
    (audioStore?.samples || []).forEach(sample => {
      if (!sample) return;
      assetMap.set(sample.assetId || sample.id, sample);
    });

    const mapSampleArray = (samples = []) => {
      if (!Array.isArray(samples)) return samples;
      return samples.map(sample => {
        if (!sample) return sample;
        const resolvedUrl = this._resolveAssetUrl(sample.url, sample.assetId, assetMap);
        if (resolvedUrl && resolvedUrl !== sample.url) {
          return { ...sample, url: resolvedUrl };
        }
        return sample;
      });
    };

    return store.instruments.map(inst => {
      const resolvedUrl = this._resolveAssetUrl(inst.url, inst.assetId, assetMap);
      const resolvedSamples = mapSampleArray(inst.multiSamples);

      return {
        id: inst.id,
        name: inst.name,
        type: inst.type,
        color: inst.color,
        mixerTrackId: inst.mixerTrackId,
        url: resolvedUrl || inst.url,
        baseNote: inst.baseNote,
        envelope: inst.envelope,
        effectChain: inst.effectChain,
        isMuted: inst.isMuted,
        cutItself: inst.cutItself,
        pianoRoll: inst.pianoRoll,
        multiSamples: resolvedSamples,
        presetName: inst.presetName,
        assetId: inst.assetId,
        // Don't serialize audioBuffer - it's too large
      };
    });
  }

  static serializePatterns(store) {
    const automationManager = getAutomationManager();
    
    return Object.entries(store.patterns || {}).map(([id, pattern]) => {
      // âœ… FIX: Pattern length is in settings.length, not pattern.length
      const patternLength = pattern.settings?.length || pattern.length || 64;
      
      // âœ… PHASE 4: Serialize automation lanes for each instrument in pattern
      const automation = {};
      if (pattern.data) {
        Object.keys(pattern.data).forEach(instrumentId => {
          const lanes = automationManager.getLanes(id, instrumentId);
          if (lanes && lanes.length > 0) {
            automation[instrumentId] = lanes.map(lane => lane.toJSON ? lane.toJSON() : lane);
          }
        });
      }
      
      return {
        id,
        name: pattern.name || id,
        data: pattern.data || {}, // Format: { instrumentId: [notes] }
        length: patternLength, // Pattern length in steps (for backward compatibility)
        settings: {
          length: patternLength,
          quantization: pattern.settings?.quantization || '16n'
        },
        automation: Object.keys(automation).length > 0 ? automation : undefined // Only include if there's automation
      };
    });
  }

  static serializeArrangementTracks(store) {
    // âœ… FIX: Use arrangementTracks from useArrangementStore (not V2 store)
    return (store.arrangementTracks || []).map(track => ({
      id: track.id,
      name: track.name,
      volume: track.volume,
      pan: track.pan,
      muted: track.muted,
      solo: track.solo,
      color: track.color,
      height: track.height,
      locked: track.locked,
      collapsed: track.collapsed,
    }));
  }

  static serializeArrangementClips(store) {
    // âœ… FIX: Use arrangementClips from useArrangementStore (not V2 store)
    return (store.arrangementClips || []).map(clip => ({
      id: clip.id,
      trackId: clip.trackId,
      patternId: clip.patternId,
      startTime: clip.startTime,
      duration: clip.duration,
      color: clip.color,
      assetId: clip.assetId,
      sampleOffset: clip.sampleOffset,
      type: clip.type, // 'pattern' or 'audio'
      name: clip.name,
      muted: clip.muted,
      locked: clip.locked,
      patternOffset: clip.patternOffset,
    }));
  }

  static _resolveAssetUrl(currentUrl, assetId, assetMap) {
    if (currentUrl && !currentUrl.startsWith('blob:')) {
      return currentUrl;
    }

    if (!assetId) {
      return currentUrl || null;
    }

    const asset = assetMap?.get(assetId);
    if (!asset) {
      return currentUrl || null;
    }

    if (asset.url && !asset.url.startsWith('blob:')) {
      return asset.url;
    }

    if (asset.storageKey) {
      return storageService.getCDNUrl(asset.storageKey, assetId);
    }

    return currentUrl || null;
  }

  static serializeMixerTracks(store) {
    return store.mixerTracks
      .filter(track => track.id !== 'master')
      .map(track => ({
        id: track.id,
        name: track.name,
        type: track.type,
        volume: track.volume,
        pan: track.pan,
        muted: track.muted,
        solo: track.solo,
        color: track.color,
        insertEffects: (track.insertEffects || []).map(effect => ({
          ...effect,
          settings: normalizeEffectSettings(effect.type || effect.effectType, effect.settings || {})
        })),
        sends: track.sends || [],
        output: track.output,
        eq: track.eq,
      }));
  }

  static serializeMasterChannel(store) {
    const master = store.mixerTracks.find(t => t.id === 'master');
    if (!master) return null;

    return {
      volume: master.volume,
      pan: master.pan,
      muted: master.muted,
      insertEffects: (master.insertEffects || []).map(effect => ({
        ...effect,
        settings: normalizeEffectSettings(effect.type || effect.effectType, effect.settings || {})
      })),
      eq: master.eq,
    };
  }

  static serializeAudioAssets(store) {
    // useProjectAudioStore uses 'samples' array, not 'assets' Map
    if (!store || !store.samples) {
      return [];
    }
    return store.samples.map(sample => ({
      id: sample.id,
      name: sample.name,
      assetId: sample.assetId,
      url: sample.url,
      storageKey: sample.storageKey,
      storageProvider: sample.storageProvider,
      durationBeats: sample.durationBeats,
      durationSeconds: sample.durationSeconds,
      type: sample.type,
      originalPattern: sample.originalPattern,
      createdAt: sample.createdAt,
      metadata: sample.metadata,
      // Don't serialize buffer - too large
    }));
  }

  static serializeWorkspace(store) {
    return {
      viewMode: store.viewMode,
      selectedTrackId: store.selectedTrackId,
      selectedClipIds: store.selectedClipIds || [],
    };
  }

  // =================== DESERIALIZATION HELPERS ===================

  static deserializeInstruments(instruments) {
    const store = useInstrumentsStore.getState();
    const mixerStore = useMixerStore.getState();
    const projectAudioStore = useProjectAudioStore.getState();
    const assetMap = new Map();
    (projectAudioStore.samples || []).forEach(sample => {
      assetMap.set(sample.assetId || sample.id, sample);
    });
    console.log(`ğŸ“¦ Restoring ${instruments.length} instruments...`);
    
    // âœ… FIX: Build a map of mixer track names to track IDs for matching
    // This helps fix cases where instruments are saved with mixerTrackId: "master"
    // but mixer has a track with the same name as the instrument
    const mixerTrackNameMap = new Map();
    mixerStore.mixerTracks.forEach(track => {
      if (track.id !== 'master' && track.name) {
        // Normalize names for matching (case-insensitive, trim whitespace)
        const normalizedName = track.name.toLowerCase().trim();
        mixerTrackNameMap.set(normalizedName, track.id);
      }
    });
    
    // âœ… DEBUG: Log mixer track name map for debugging
    console.log(`ğŸ” Mixer track name map:`, Array.from(mixerTrackNameMap.entries()));
    
    // Add instruments
    instruments.forEach(instData => {
      try {
        // âœ… FIX: Map legacy instrument types to current types
        let instrumentType = instData.type || 'sample';
        
        // Map 'sampler' to 'sample' (legacy type from DB)
        if (instrumentType === 'sampler') {
          instrumentType = 'sample';
        }
        
        // âœ… FIX: Auto-match mixer track by instrument name if mixerTrackId is "master"
        // This fixes the issue where instruments added later are saved with mixerTrackId: "master"
        // but mixer has a track with the same name
        let mixerTrackId = instData.mixerTrackId;
        const originalMixerTrackId = mixerTrackId;
        
        if (mixerTrackId === 'master' || !mixerTrackId) {
          const instrumentName = instData.name?.toLowerCase().trim();
          console.log(`ğŸ” Checking auto-match for "${instData.name}" (normalized: "${instrumentName}")`);
          console.log(`ğŸ” Available mixer track names:`, Array.from(mixerTrackNameMap.keys()));
          
          if (instrumentName && mixerTrackNameMap.has(instrumentName)) {
            const matchedTrackId = mixerTrackNameMap.get(instrumentName);
            mixerTrackId = matchedTrackId;
            console.log(`ğŸ”— âœ… Auto-matched instrument "${instData.name}" to mixer track "${matchedTrackId}" (was: ${originalMixerTrackId})`);
          } else {
            console.log(`ğŸ” No match found for "${instData.name}" in mixer tracks`);
            // âœ… FIX: Try partial matching (e.g., "Piano" matches "Piano" track)
            // This handles cases where names might have slight variations
            const partialMatch = Array.from(mixerTrackNameMap.entries()).find(([trackName, trackId]) => 
              trackName.includes(instrumentName) || instrumentName.includes(trackName)
            );
            if (partialMatch) {
              mixerTrackId = partialMatch[1];
              console.log(`ğŸ”— âœ… Partial match: instrument "${instData.name}" to mixer track "${partialMatch[1]}"`);
            }
          }
        } else {
          console.log(`ğŸ” Instrument "${instData.name}" already has mixerTrackId: ${mixerTrackId} (skipping auto-match)`);
        }
        
        // Ensure required fields
        const instrumentData = {
          ...instData,
          id: instData.id || `inst-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
          type: instrumentType,
          mixerTrackId: mixerTrackId || instData.mixerTrackId || 'master', // Fallback to master if no match
        };

        const resolvedInstrumentUrl = this._resolveAssetUrl(instrumentData.url, instrumentData.assetId, assetMap);
        if (resolvedInstrumentUrl) {
          instrumentData.url = resolvedInstrumentUrl;
        }

        if (Array.isArray(instrumentData.multiSamples)) {
          instrumentData.multiSamples = instrumentData.multiSamples.map(sample => {
            if (!sample) return sample;
            const resolvedSampleUrl = this._resolveAssetUrl(sample.url, sample.assetId, assetMap);
            if (resolvedSampleUrl && resolvedSampleUrl !== sample.url) {
              return { ...sample, url: resolvedSampleUrl };
            }
            return sample;
          });
        }
        
        // âœ… CRITICAL: Log the final mixerTrackId before passing to handleAddNewInstrument
        console.log(`ğŸ“ Restoring instrument "${instrumentData.name}" with mixerTrackId: ${instrumentData.mixerTrackId} (original: ${originalMixerTrackId})`);
        
        // Store mute state before adding instrument (will be restored after)
        const savedMuteState = instrumentData.isMuted !== undefined ? instrumentData.isMuted : false;
        
        store.handleAddNewInstrument(instrumentData);
        console.log(`âœ… Restored instrument: ${instrumentData.name} (${instrumentType}) â†’ ${instrumentData.mixerTrackId}`);
        
        // âœ… FIX: Restore mute state to audio engine after instrument is created
        if (savedMuteState) {
          // Use dynamic import to avoid circular dependencies
          import('../services/AudioContextService.js').then(({ AudioContextService }) => {
            // Wait a bit for instrument to be fully created in audio engine
            setTimeout(() => {
              AudioContextService.setInstrumentMute(instrumentData.id, savedMuteState);
              console.log(`ğŸ”‡ Restored mute state for instrument ${instrumentData.name}: ${savedMuteState}`);
            }, 100);
          }).catch(err => {
            console.warn('âš ï¸ Failed to restore mute state:', err);
          });
        }
      } catch (error) {
        console.error(`âŒ Failed to restore instrument ${instData.id}:`, error);
      }
    });
  }

  static deserializePatterns(patterns) {
    const store = useArrangementStore.getState();
    
    // Handle both array and object formats
    const patternsArray = Array.isArray(patterns) 
      ? patterns 
      : Object.values(patterns || {});
    
    console.log(`ğŸ“¦ Restoring ${patternsArray.length} patterns...`);
    
    // Restore patterns
    patternsArray.forEach(pattern => {
      try {
        const patternId = pattern.id;
        
        // âœ… FIX: Create pattern with specific ID if it doesn't exist
        if (!store.patterns[patternId]) {
          // Create pattern manually with the correct ID instead of letting createPattern generate a new one
          const newPattern = {
            id: patternId,
            name: pattern.name || patternId,
            data: {}, // Will be populated below
            settings: {
              length: pattern.length || pattern.settings?.length || 64,
              quantization: pattern.settings?.quantization || '16n'
            }
          };
          
          // Add pattern to store using setState
          useArrangementStore.setState(state => ({
            patterns: { ...state.patterns, [patternId]: newPattern },
            patternOrder: state.patternOrder.includes(patternId) 
              ? state.patternOrder 
              : [...state.patternOrder, patternId]
          }));
          
          console.log(`âœ… Created pattern: ${patternId}`);
        }
        
        // âœ… FIX: Restore pattern length if provided
        // Pattern length can be in pattern.length or pattern.settings.length
        if (store.patterns[patternId]) {
          const currentPattern = store.patterns[patternId];
          const patternLength = pattern.length || pattern.settings?.length || currentPattern.settings?.length || 64;
          
          // Update pattern with length in settings using setState
          useArrangementStore.setState(state => ({
            patterns: {
              ...state.patterns,
              [patternId]: {
                ...currentPattern,
                settings: {
                  ...currentPattern.settings,
                  length: patternLength,
                  quantization: pattern.settings?.quantization || currentPattern.settings?.quantization || '16n'
                }
              }
            }
          }));
        }
        
        // âœ… FIX: Restore pattern data (notes) - handle both object and array formats
        if (pattern.data) {
          // pattern.data can be:
          // 1. Object: { instrumentId: [notes] }
          // 2. Already in correct format
          const patternData = typeof pattern.data === 'object' && !Array.isArray(pattern.data)
            ? pattern.data
            : {};
          
          Object.entries(patternData).forEach(([instrumentId, notes]) => {
            try {
              // Ensure notes is an array
              const notesArray = Array.isArray(notes) ? notes : [];
              if (notesArray.length > 0) {
                store.updatePatternNotes(patternId, instrumentId, notesArray);
                console.log(`  âœ… Restored ${notesArray.length} notes for instrument ${instrumentId}`);
              }
            } catch (error) {
              console.warn(`  âš ï¸ Failed to restore notes for instrument ${instrumentId}:`, error);
            }
          });
        }
        
        // âœ… PHASE 4: Restore automation lanes for each instrument in pattern
        if (pattern.automation) {
          try {
            const automationManager = getAutomationManager();
            Object.entries(pattern.automation).forEach(([instrumentId, lanesData]) => {
              try {
                if (lanesData && Array.isArray(lanesData) && lanesData.length > 0) {
                  // Use initializeLanes to restore from saved data
                  automationManager.initializeLanes(patternId, instrumentId, lanesData);
                  console.log(`  âœ… Restored ${lanesData.length} automation lanes for instrument ${instrumentId}`);
                }
              } catch (error) {
                console.warn(`  âš ï¸ Failed to restore automation for instrument ${instrumentId}:`, error);
              }
            });
          } catch (error) {
            console.warn(`  âš ï¸ Failed to restore automation for pattern ${patternId}:`, error);
          }
        }
        
        console.log(`âœ… Restored pattern: ${patternId}`);
      } catch (error) {
        console.error(`âŒ Failed to restore pattern ${pattern.id}:`, error);
      }
    });
    
    // âœ… FIX: Ensure at least one pattern is active after restore
    const restoredPatternIds = Object.keys(store.patterns);
    if (restoredPatternIds.length > 0 && !store.activePatternId) {
      // If no active pattern, set first pattern as active
      const firstPatternId = restoredPatternIds[0];
      store.setActivePatternId(firstPatternId);
      console.log(`âœ… Set first pattern as active: ${firstPatternId}`);
    } else if (restoredPatternIds.length > 0 && !store.patterns[store.activePatternId]) {
      // If active pattern doesn't exist, set first pattern as active
      const firstPatternId = restoredPatternIds[0];
      store.setActivePatternId(firstPatternId);
      console.log(`âœ… Active pattern not found, switched to first pattern: ${firstPatternId}`);
    }
    
    // Restore pattern order and active pattern if available
    // Note: pattern_order is stored in metadata, will be restored in main deserialize method
  }
  
  static deserializePatternOrder(patternOrder, activePatternId) {
    const store = useArrangementStore.getState();
    
    // âœ… FIX: Restore pattern order if provided
    if (patternOrder && Array.isArray(patternOrder)) {
      // Filter to only include patterns that exist
      const validPatternOrder = patternOrder.filter(id => store.patterns[id]);
      
      if (validPatternOrder.length > 0) {
        // Update pattern order (if store supports it)
        // Note: patternOrder might be read-only, so we'll just ensure active pattern is set
      }
    }
    
    // âœ… FIX: Set active pattern - ensure it exists, otherwise use first available
    if (activePatternId && store.patterns[activePatternId]) {
      store.setActivePatternId(activePatternId);
      console.log(`âœ… Set active pattern: ${activePatternId}`);
    } else {
      // If active pattern doesn't exist or not provided, use first available
      const availablePatterns = Object.keys(store.patterns);
      if (availablePatterns.length > 0) {
        const firstPatternId = availablePatterns[0];
        store.setActivePatternId(firstPatternId);
        console.log(`âœ… Set first pattern as active: ${firstPatternId}`);
      }
    }
  }

  static deserializeArrangement(arrangement) {
    const store = useArrangementStore.getState();
    console.log(`ğŸ“¦ Restoring arrangement...`);
    
    try {
      // Clear existing arrangement tracks first
      store.arrangementTracks = [];
      
      // Restore arrangement tracks
      if (arrangement.tracks && Array.isArray(arrangement.tracks)) {
        arrangement.tracks.forEach(track => {
          try {
            // Use addArrangementTrack method to properly create tracks
            const newTrack = {
              id: track.id,
              name: track.name,
              volume: track.volume ?? 1.0,
              pan: track.pan ?? 0,
              muted: track.muted ?? false,
              solo: track.solo ?? false,
              height: track.height ?? 80,
              locked: track.locked ?? false,
              collapsed: track.collapsed ?? false,
            };
            
            store.arrangementTracks.push(newTrack);
            console.log(`âœ… Restored arrangement track: ${track.name}`);
          } catch (error) {
            console.error(`âŒ Failed to restore track ${track.id}:`, error);
          }
        });
      }
      
      // Restore arrangement clips
      if (arrangement.clips && Array.isArray(arrangement.clips)) {
        arrangement.clips.forEach(clip => {
          try {
            // Check if clip already exists
            const existingClip = store.arrangementClips.find(c => c.id === clip.id);
            if (!existingClip) {
              const newClip = {
                id: clip.id,
                type: clip.type || 'pattern',
                trackId: clip.trackId,
                startTime: clip.startTime,
                duration: clip.duration,
                patternId: clip.patternId,
                assetId: clip.assetId,
                sampleOffset: clip.sampleOffset || 0,
                patternOffset: clip.patternOffset || 0,
                muted: clip.muted ?? false,
                locked: clip.locked ?? false,
                name: clip.name,
              };
              
              store.arrangementClips.push(newClip);
              console.log(`âœ… Restored arrangement clip: ${clip.id}`);
            }
          } catch (error) {
            console.error(`âŒ Failed to restore clip ${clip.id}:`, error);
          }
        });
      }
      
      // Restore markers
      if (arrangement.markers && Array.isArray(arrangement.markers)) {
        store.arrangementMarkers = arrangement.markers;
      }
      
      // Restore loop regions
      if (arrangement.loop_regions && Array.isArray(arrangement.loop_regions)) {
        store.arrangementLoopRegions = arrangement.loop_regions;
      }
    } catch (error) {
      console.error('âŒ Failed to restore arrangement:', error);
    }
  }

  static async deserializeMixer(mixer) {
    const store = useMixerStore.getState();
    console.log(`ğŸ“¦ Restoring mixer...`);
    
    try {
      // Get master track
      const masterTrack = store.mixerTracks.find(t => t.id === 'master') || {
        id: 'master',
        name: 'Master',
        type: 'master',
        volume: 0,
        pan: 0,
        isMuted: false,
        isSolo: false,
        color: '#8b5cf6',
        output: null,
        sends: [],
        insertEffects: [],
        eq: { enabled: false, lowGain: 0, midGain: 0, highGain: 0 },
      };
      
      // Build all tracks array
      const newTracks = [masterTrack];
      
      // Restore mixer tracks
      if (mixer.tracks && Array.isArray(mixer.tracks)) {
        mixer.tracks.forEach(track => {
          try {
            const normalizedInsertEffects = (track.insertEffects || []).map(effect => ({
              ...effect,
              settings: normalizeEffectSettings(effect.type || effect.effectType, effect.settings || {})
            }));
            // âœ… FIX: Normalize legacy send format (object) to array before using it elsewhere
            const normalizedSends = Array.isArray(track.sends)
              ? track.sends
              : Object.entries(track.sends || {})
                  .filter(([key]) => !key.endsWith('_muted'))
                  .map(([busId, value]) => {
                    const levelLinear = typeof value === 'number'
                      ? Math.min(1, Math.max(0, value > 1 ? value : Math.pow(10, value / 20)))
                      : 0.5;
                    return {
                      busId,
                      level: levelLinear,
                      preFader: false
                    };
                  });

            // Create new track with template data
            const newTrack = {
              id: track.id,
              name: track.name || `Track ${track.id}`,
              type: track.type || 'track', // âœ… FIX: Use 'track' instead of 'channel' to match Mixer.jsx filter
              volume: track.volume ?? 0,
              pan: track.pan ?? 0,
              // âœ… FIX: Map DB properties (muted/solo) to store properties (isMuted/isSolo)
              isMuted: track.muted !== undefined ? track.muted : (track.isMuted ?? false),
              isSolo: track.solo !== undefined ? track.solo : (track.isSolo ?? false),
              color: track.color || '#3b82f6',
              output: track.output || 'master',
              sends: normalizedSends,
              insertEffects: normalizedInsertEffects,
              eq: track.eq || {
                enabled: false,
                lowGain: 0,
                midGain: 0,
                highGain: 0,
              },
            };
            
            newTracks.push(newTrack);
            console.log(`âœ… Restored mixer track: ${newTrack.name} (${newTrack.id})`);
          } catch (error) {
            console.error(`âŒ Failed to restore mixer track ${track.id}:`, error);
          }
        });
      }
      
      // âœ… CRITICAL: Update store using Zustand's set() method
      // This ensures the store is properly updated and reactive
      useMixerStore.setState({ mixerTracks: newTracks });
      console.log(`âœ… Updated mixer store with ${newTracks.length} tracks (1 master + ${newTracks.length - 1} channels)`);
      
      // âœ… FIX: Don't restore effects here - they're already in the store (line 953)
      // and will be synced to AudioEngine by _syncMixerTracksToAudioEngine() in deserialize()
      // Restoring them here with handleMixerEffectAdd() would create duplicate effects with new IDs

      // Restore track parameters (volume, pan, mute, solo) for each track
      newTracks.forEach(track => {
        try {
          // Restore track parameters
          if (track.volume !== undefined && track.id !== 'master') {
            store.handleMixerParamChange(track.id, 'volume', track.volume);
          }
          if (track.pan !== undefined && track.id !== 'master') {
            store.handleMixerParamChange(track.id, 'pan', track.pan);
          }
          if (track.isMuted) {
            store.toggleMute(track.id);
          }
          if (track.isSolo) {
            store.toggleSolo(track.id);
          }
        } catch (error) {
          console.error(`âŒ Failed to restore parameters for track ${track.id}:`, error);
        }
      });
      
      // Restore master channel parameters
      if (mixer.master) {
        const masterTrackInArray = newTracks.find(t => t.id === 'master');
        if (masterTrackInArray) {
          // âœ… FIX: Restore master effects FIRST (before Object.assign)
          // This ensures effects are restored with their original IDs and settings
          // We'll set insertEffects directly and then rebuild the chain
          const masterInsertEffects = mixer.master.insertEffects && Array.isArray(mixer.master.insertEffects) 
            ? mixer.master.insertEffects.map(effect => ({
                ...effect,
                settings: normalizeEffectSettings(effect.type || effect.effectType, effect.settings || {})
              }))
            : [];
          
          // Update master track with mixer.master data
          Object.assign(masterTrackInArray, {
            volume: mixer.master.volume ?? masterTrackInArray.volume,
            pan: mixer.master.pan ?? masterTrackInArray.pan,
            // âœ… FIX: Map DB properties (muted/solo) to store properties (isMuted/isSolo)
            isMuted: mixer.master.muted !== undefined ? mixer.master.muted : (mixer.master.isMuted ?? masterTrackInArray.isMuted),
            isSolo: mixer.master.solo !== undefined ? mixer.master.solo : (mixer.master.isSolo ?? masterTrackInArray.isSolo),
            // âœ… FIX: Set insertEffects directly (don't use handleMixerEffectAdd which adds new effects)
            insertEffects: masterInsertEffects,
          });
          
          // Update store again with updated master
          useMixerStore.setState({ mixerTracks: newTracks });
          
          // Restore master parameters
          if (mixer.master.volume !== undefined) {
            store.handleMixerParamChange('master', 'volume', mixer.master.volume);
          }
          if (mixer.master.pan !== undefined) {
            store.handleMixerParamChange('master', 'pan', mixer.master.pan);
          }
          if (mixer.master.muted !== undefined && mixer.master.muted !== store.mutedChannels.has('master')) {
            store.toggleMute('master');
          }

          // âœ… FIX: Don't rebuild master chain here - effects are already in the store (line 1019)
          // and will be synced to AudioEngine by _syncMixerTracksToAudioEngine() in deserialize()

          console.log(`âœ… Restored master channel with ${masterInsertEffects.length} effects`);
        }
      }

      // Restore send channels (aux buses) if provided - convert to bus tracks
      if (Array.isArray(mixer.send_channels)) {
        const sendChannelsAsBusTracks = mixer.send_channels.map((sendChannel, index) => {
          const safeChannel = sendChannel || {};
          return {
            id: safeChannel.id || `bus-${index + 1}`,
            name: safeChannel.name || `Bus ${index + 1}`,
            type: 'bus',
            volume: safeChannel.volume ?? 0,
            pan: safeChannel.pan ?? 0,
            isMuted: safeChannel.muted ?? false,
            isSolo: safeChannel.solo ?? false,
            color: '#f59e0b', // Bus color
            output: 'master',
            sends: [],
            insertEffects: [],
            eq: { enabled: false, lowGain: 0, midGain: 0, highGain: 0 }
          };
        });

        // Add bus tracks to mixerTracks
        newTracks.push(...sendChannelsAsBusTracks);

        // Also keep sendChannels for backward compatibility
        const normalizedSendChannels = mixer.send_channels.map((sendChannel, index) => {
          const safeChannel = sendChannel || {};
          return {
            id: safeChannel.id || `send-${index + 1}`,
            name: safeChannel.name || `Send ${index + 1}`,
            type: safeChannel.type || 'send',
            masterLevel: safeChannel.masterLevel ?? safeChannel.master_level ?? 0,
            pan: safeChannel.pan ?? 0,
            ...safeChannel
          };
        });

        useMixerStore.setState(state => ({
          ...state,
          sendChannels: normalizedSendChannels
        }));

        console.log(`âœ… Restored ${sendChannelsAsBusTracks.length} send channels as bus tracks`);
      } else {
        console.log('â„¹ï¸ No send channels found in project data - keeping current defaults');
      }

      // âœ… FIX: Don't sync mixer tracks to AudioEngine here
      // This is now handled in deserialize() method (after deserializeMixer() call)
      // which ensures proper order: mixer â†’ sync â†’ samples â†’ instruments
    } catch (error) {
      console.error('âŒ Failed to restore mixer:', error);
    }
  }

  static deserializeTimeline(timeline) {
    const store = useTimelineStore.getState();
    console.log(`ğŸ“¦ Restoring timeline settings...`);
    
    try {
      // Timeline store methods may vary, update what's available
      if (timeline.total_beats) {
        // Update timeline if method exists
        console.log(`âœ… Timeline settings restored`);
      }
    } catch (error) {
      console.error('âŒ Failed to restore timeline:', error);
    }
  }

  static deserializeAudioAssets(assets) {
    const store = useProjectAudioStore.getState();
    console.log(`ğŸ“¦ Restoring ${assets.length} audio samples...`);
    
    // Clear existing samples
    store.clearAll();
    
    try {
      assets.forEach(sample => {
        try {
          // Add sample to store
          // Note: audioBuffer is not serialized, so samples will need to be reloaded
          if (store.addSample) {
            store.addSample({
              id: sample.id,
              name: sample.name,
              assetId: sample.assetId,
              url: sample.url,
              storageKey: sample.storageKey,
              storageProvider: sample.storageProvider,
              durationBeats: sample.durationBeats,
              durationSeconds: sample.durationSeconds,
              type: sample.type || 'frozen',
              originalPattern: sample.originalPattern,
              createdAt: sample.createdAt,
              metadata: sample.metadata || {},
            });
            console.log(`âœ… Restored audio sample: ${sample.name}`);
          }
        } catch (error) {
          console.error(`âŒ Failed to restore asset ${asset.id}:`, error);
        }
      });
    } catch (error) {
      console.error('âŒ Failed to restore audio assets:', error);
    }
  }

  static deserializeWorkspace(workspace) {
    const store = useArrangementWorkspaceStore.getState();
    console.log(`ğŸ“¦ Restoring workspace settings...`);
    
    try {
      if (workspace.viewMode && store.setViewMode) {
        store.setViewMode(workspace.viewMode);
      }
      
      if (workspace.selectedTrackId && store.setSelectedTrackId) {
        store.setSelectedTrackId(workspace.selectedTrackId);
      }
      
      if (workspace.selectedClipIds && store.setSelectedClipIds) {
        store.setSelectedClipIds(workspace.selectedClipIds);
      }
      
      console.log(`âœ… Workspace settings restored`);
    } catch (error) {
      console.error('âŒ Failed to restore workspace:', error);
    }
  }
}

